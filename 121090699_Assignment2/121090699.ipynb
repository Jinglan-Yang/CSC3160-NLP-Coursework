{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 2\n",
        "\n",
        "In this assignment, we will focus on regular expressions and byte-pair encoding. Assignment 2 is worth 10% toward your final grade."
      ],
      "metadata": {
        "id": "f6iyutoXsYxR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [50 marks] Regular expression\n",
        "\n",
        "1. [30marks] Write python code with regular expressions to clean the html webpage.\n",
        "\n",
        "  Input: https://slpcourse.github.io/materials/html_page.txt\n",
        "\n",
        "  Reference Output: https://slpcourse.github.io/materials/reference.txt\n",
        "\n",
        "2. [20 marks] Based on the output from 1, extract the lines with lecture time, tutorial time and office hours. Your need to use regular expressions.\n",
        "\n",
        "\n",
        "Note: We expect the regular expressions to be just enough for the task. If there are extra non-used regular expressions, we will deduct scores based the lines of non-used regular expressions. Each line that contains non-used regular expressions is worth 5 marks. Each uncleaned html tag is worth 2 points. Each unnecessary whitespace is worth 1 point."
      ],
      "metadata": {
        "id": "TT3nsKxz2UbJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## question 1.\n",
        "import re\n",
        "import requests\n",
        "\n",
        "url = \"https://slpcourse.github.io/materials/html_page.txt\"\n",
        "\n",
        "response = requests.get(url)\n",
        "html_content = response.text\n",
        "\n",
        "def clean_html(raw_html):\n",
        "  # Clean html tags\n",
        "  pattern = r'<a\\s+[^>]*>(.*?)</a>' # URL pattern in HTML webpage\n",
        "  withoutURL_html = re.sub(pattern, r'\\1', raw_html, flags=re.DOTALL) # delete URL\n",
        "\n",
        "  # Remove all other HTML tags\n",
        "  withoutTags_text = re.sub('<.*?>', '', withoutURL_html)\n",
        "\n",
        "  # Clean unnecessary white space\n",
        "  withoutIndent_text = re.sub('\\t+', '', withoutTags_text) # delete indent spaces\n",
        "  withoutBlanklines_text = re.sub('\\n+', '\\n', withoutIndent_text) # delete blank new lines\n",
        "  cleantext = re.sub('\\n ', '\\n', withoutBlanklines_text) # deleting white space to left align all text\n",
        "\n",
        "  return cleantext.strip()\n",
        "\n",
        "# Clean the HTML content\n",
        "cleaned_text = clean_html(html_content)\n",
        "\n",
        "# Display the cleaned text for verification\n",
        "print(cleaned_text)"
      ],
      "metadata": {
        "id": "FjKVgSWFtmwq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43e0f750-ab8f-4fb4-b9d1-679f15796fff"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSC3160 Fundamentals of Speech and Language Processing\n",
            "MDS6002 Natural Language Processing\n",
            "Spring 2023\n",
            "The difference between speech and language processing and other data processing is the use of knowledge\n",
            "of language. In this course, we will study how to describe, process and compute different levels of\n",
            "language knowledge including Phonetics and Phonology, Morphology, Syntax, Semantics, and how the\n",
            "language knowledge is used in speech and language applications such as named entities recognition,\n",
            "information extraction, question answering, speech recognition, and speech synthesis.\n",
            "Teaching team\n",
            "Instructor  Zhizheng Wu\n",
            "TA  Xi Chen\n",
            "TA Xueyao Zhang\n",
            "Poster Session\n",
            "A final project poster session is planned by the end of the course (tentatively May 20th 2023). This\n",
            "is to provide students the opportunities to connect with speech and language research/industry\n",
            "community.\n",
            "Anyone from the CUHK-Shenzhen and speech and language technology community are welcome to join. More\n",
            "details will be provided when it is close to the event. Feel free to reach out!\n",
            "Logistics\n",
            "Lectures: are on Tuesday/Thursday 4:00PM - 5:20PM in TB103. Note: lectures will be remote\n",
            "for the first two weeks, and hybrid afterwards. The Zoom link is posted on BB.\n",
            "Office hours \n",
            "Zhizheng Wu: Thu 2:30-3:30 PM. Daoyuan Building 321b\n",
            "Xi Chen: Wed 7-9PM. SDS Research Lab (4th Floor, Zhi Xin Building) Seat No.100\n",
            "Xueyao Zhang: Wed 7-9PM. SDS Research Lab (4th Floor, Zhi Xin Building) Seat No.78\n",
            "Contact: If you have any question, please reach out to us via email or post it to BB.\n",
            "Course Information\n",
            "This course is designed as the first course for students who are interested in speech and language\n",
            "technology. The first half of the course focuses on the fundamentals and introduces tools for\n",
            "students to use, and the second half emphasises on applications, giving students the opportunity to\n",
            "know how speech and language technology could impact human life.\n",
            "In particular, the topics include:\n",
            "Understanding human speech: spectrogram, fundamental frequency, formant, etc \n",
            "Human sounds and their organization \n",
            "Words and their relationship to other words \n",
            "Syntax: Structure of sentences \n",
            "Text processing and regular expressions \n",
            "Language models \n",
            "Embedding: Representations of the meaning of words \n",
            "Word classifications and Named entities recognition \n",
            "Applications: speech recognition, speech synthesis, machine translation, chatbot, etc\n",
            "Prerequisites\n",
            "Proficiency in LaTex:  All the reports need to be written by using LaTex. A template will be\n",
            "provided. If you are not familiar with LaTex, please learn from the tutorial in advance.\n",
            "Proficiency in GitHub:  All the source codes need to be submitted in GitHub. \n",
            "Proficiency in Python: All the assignments will be in Python (using Numpy and PyTorch). \n",
            "Basic machine learning knowledge:  It is possible to take this course without any machine\n",
            "learning knowledge, however, the course will be easier if you have foundations of machine learning.\n",
            "Basic Concepts of probability:  It will be easier for you to understand some lectures if you\n",
            "know basics of probability. \n",
            "Textbooks\n",
            "Recommended Books:\n",
            "Speech and Language Processing\n",
            "(3rd ed. draft), by Dan Jurafsky and James H. Martin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## question 2.\n",
        "# extract instructor's and TA's names.\n",
        "Instructor_name=re.compile(r'Instructor.*').findall(cleaned_text)\n",
        "Instructor_name=Instructor_name[0].split('Instructor')[1].strip()\n",
        "TA_names=re.compile(r'TA.*').findall(cleaned_text)\n",
        "TA_names1=TA_names[0].split('TA')[1].strip()\n",
        "TA_names2=TA_names[1].split('TA')[1].strip()\n",
        "\n",
        "# Get lecture time\n",
        "lecture_time = re.compile(r'Lectures[^.!?]*').findall(cleaned_text)[0]\n",
        "print(\"Lecture time: \")\n",
        "print(lecture_time)\n",
        "\n",
        "# Get tutorial time\n",
        "tutorial_time = re.compile(r'[^.!?]*tutorial[^.!?]*').findall(cleaned_text)\n",
        "print(\"\\nTutorial time: \")\n",
        "print(tutorial_time)\n",
        "print(\"From the text above, we know there is no offline tutorial.\\n\")\n",
        "\n",
        "# use 'Office hours', name of instructor, and names of TAs to locate office hours.\n",
        "office_hours=re.compile('Office hours.*%s.*%s.*%s[^\\n]*'%(Instructor_name,TA_names1,TA_names2), re.MULTILINE|re.DOTALL).findall(cleaned_text)[0]\n",
        "print(office_hours)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFxY_HiGdJHR",
        "outputId": "02da926f-143e-4f51-e442-7849da0f2037"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lecture time: \n",
            "Lectures: are on Tuesday/Thursday 4:00PM - 5:20PM in TB103\n",
            "\n",
            "Tutorial time: \n",
            "[' If you are not familiar with LaTex, please learn from the tutorial in advance']\n",
            "From the text above, we know there is no offline tutorial.\n",
            "\n",
            "Office hours \n",
            "Zhizheng Wu: Thu 2:30-3:30 PM. Daoyuan Building 321b\n",
            "Xi Chen: Wed 7-9PM. SDS Research Lab (4th Floor, Zhi Xin Building) Seat No.100\n",
            "Xueyao Zhang: Wed 7-9PM. SDS Research Lab (4th Floor, Zhi Xin Building) Seat No.78\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [50 marks] Byte-pair encoding\n",
        "\n",
        "In this assignment, the task is to implement a Byte-Pair Encoding (BPE) algorithm to learn subword tokens.\n",
        "\n",
        "Here is a vocabulary with frequency,\n",
        "```\n",
        "2 oneumonoultramicroscopicsilicovolcanoconiosis\n",
        "5 hippopotomonstrosesquippedaliophobia\n",
        "4 supercalifragilisticexpialidocious\n",
        "1 pseudopseudohypoparathyroidism\n",
        "6 floccinaucinihilipilification\n",
        "2 antidisestablishmentarianism\n",
        "5 honorificabilitudinitatibus\n",
        "```\n",
        "The first column represents the occurency frequency, and the second column represents the words.\n",
        "\n",
        "In the implementation, k is set to be 5."
      ],
      "metadata": {
        "id": "8TD1kIfo1emC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "import re\n",
        "\n",
        "# Count numbers of adjacent tokens\n",
        "def get_stats(vocab):\n",
        "  pairs = defaultdict(int)\n",
        "  for word, freq in vocab.items():\n",
        "    symbols = word.split()\n",
        "    for i in range(len(symbols) - 1):\n",
        "      pairs[symbols[i], symbols[i + 1]] += freq\n",
        "  return pairs\n",
        "\n",
        "def merge_vocab(pair, v_in):\n",
        "    v_out = {}\n",
        "    bigram = re.escape(' '.join(pair))\n",
        "    p = re.compile(r'(?<!\\S)' + bigram + r'(?!\\S)')\n",
        "    for word in v_in:\n",
        "      w_out = p.sub(''.join(pair), word)\n",
        "      v_out[w_out] = v_in[word]\n",
        "    return v_out\n",
        "\n",
        "def bpe(vocab, K):\n",
        "  for i in range(K):\n",
        "    pairs = get_stats(vocab)\n",
        "    if not pairs:\n",
        "        break\n",
        "    best = max(pairs, key=pairs.get)\n",
        "    print('The most frequent pair of adjacent tokens in round '+str(i)+': ',best)\n",
        "    vocab = merge_vocab(best, vocab)\n",
        "  return vocab\n",
        "\n",
        "# Input vocabulary with frequency\n",
        "vocab = {\"oneumonoultramicroscopicsilicovolcanoconiosis\": 2,\n",
        "         \"hippopotomonstrosesquippedaliophobia\": 5,\n",
        "         \"supercalifragilisticexpialidocious\": 4,\n",
        "         \"pseudopseudohypoparathyroidism\": 1,\n",
        "         \"floccinaucinihilipilification\": 6,\n",
        "         \"antidisestablishmentarianism\": 2,\n",
        "         \"honorificabilitudinitatibus\": 5}\n",
        "\n",
        "# Convert each word in the vocabulary to a space-separated string of characters\n",
        "vocab = {(' '.join(word) + ' _'): freq for word, freq in vocab.items()}\n",
        "\n",
        "# Number of merges\n",
        "K = 5\n",
        "\n",
        "# Perform BPE\n",
        "bpe_vocab = bpe(vocab, K)\n",
        "\n",
        "# Display the modified vocabulary\n",
        "print('The vocabulary after merging 5 times using BPE algorithm: ')\n",
        "bpe_vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYSt1UmgCFXA",
        "outputId": "b27baa10-7ff3-4531-eeeb-e6ef7f1dfbfe"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The most frequent pair of adjacent tokens in round 0:  ('l', 'i')\n",
            "The most frequent pair of adjacent tokens in round 1:  ('i', 'li')\n",
            "The most frequent pair of adjacent tokens in round 2:  ('o', 'n')\n",
            "The most frequent pair of adjacent tokens in round 3:  ('i', 'c')\n",
            "The most frequent pair of adjacent tokens in round 4:  ('i', 'n')\n",
            "The vocabulary after merging 5 times using BPE algorithm: \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'on e u m on o u l t r a m ic r o s c o p ic s ili c o v o l c a n o c on i o s i s _': 2,\n",
              " 'h i p p o p o t o m on s t r o s e s q u i p p e d a li o p h o b i a _': 5,\n",
              " 's u p e r c a li f r a g ili s t ic e x p i a li d o c i o u s _': 4,\n",
              " 'p s e u d o p s e u d o h y p o p a r a t h y r o i d i s m _': 1,\n",
              " 'f l o c c in a u c in i h ili p ili f ic a t i on _': 6,\n",
              " 'a n t i d i s e s t a b li s h m e n t a r i a n i s m _': 2,\n",
              " 'h on o r i f ic a b ili t u d in i t a t i b u s _': 5}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l_5ehKozAKBX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}